{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras import models\n",
    "# import tensorflow.keras.utils\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras.utils\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/mnt/data/ml/ShowJetsData1.npz')\n",
    "# !ls /mnt/data/ml/\n",
    "images = data['jetImages']\n",
    "labels = data['labels']\n",
    "grid = np.size(images, 1)\n",
    "#ensure same number of signal vs. background and even split of z events\n",
    "qcd_im = images[np.where(labels[:,0] == 1)]\n",
    "if len(qcd_im) % 3 != 0:\n",
    "    qcd_im = qcd_im[:len(qcd_im)-(len(qcd_im) % 3)]\n",
    "z1_im = images[np.where(labels[:,1] == 1)]\n",
    "z1_im = z1_im[:int(len(qcd_im)/3)]\n",
    "z2_im = images[np.where(labels[:,2] == 1)]\n",
    "z2_im = z2_im[:int(len(qcd_im)/3)]\n",
    "z3_im = images[np.where(labels[:,3] == 1)]\n",
    "z3_im = z3_im[:int(len(qcd_im)/3)]\n",
    "print(len(z1_im), len(z2_im), len(z3_im), len(qcd_im))\n",
    "qcd_lab = np.zeros([len(qcd_im), 2])\n",
    "qcd_lab[:,0] = 1\n",
    "z_lab = np.zeros([len(qcd_im), 2])\n",
    "z_lab[:,1] = 1\n",
    "images = np.vstack((qcd_im, z1_im, z2_im, z3_im))\n",
    "labels = np.vstack((qcd_lab, z_lab))\n",
    "n_data = len(images)\n",
    "images = images.reshape(n_data, grid, grid, 1)\n",
    "#split data into testing/training/validation\n",
    "\n",
    "testimages = images[::4]\n",
    "testlabels = labels[::4]\n",
    "mask_im = np.ones(images.shape,dtype=bool)\n",
    "mask_im[::4] = 0\n",
    "mask_im[1::8] = 0\n",
    "mask_lab = np.ones(labels.shape,dtype=bool)\n",
    "mask_lab[::4] = 0\n",
    "mask_lab[1::8] = 0\n",
    "valimages = images[1::8]\n",
    "vallabels = labels[1::8]\n",
    "\n",
    "trainimages = images[mask_im].reshape((n_data-len(testimages)-len(valimages)), grid, grid, 1)\n",
    "trainlabels = labels[mask_lab].reshape((n_data-len(testimages)-len(valimages)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a plot of data to see what it looks like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing -> spit data into training and testing; take 80% for training and 20% for testing.\n",
    "\n",
    "If using CNN, uncomment \".reshape(n_data, grid, grid, 1)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3d7b13c84619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#plot input signal and background\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msig_trainimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbkg_trainimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrainlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "#plot input signal and background\n",
    "sig_trainimages = np.zeros_like(trainimages[1])\n",
    "bkg_trainimages = np.zeros_like(trainimages[1])\n",
    "for i in range(len(trainimages)):\n",
    "    if trainlabels[i,0] == 1:\n",
    "        sig_trainimages += trainimages[i]\n",
    "    else:\n",
    "        bkg_trainimages += trainimages[i]\n",
    "display_sig = sig_trainimages.reshape(grid,grid)\n",
    "plt.grid(False)\n",
    "plt.imshow(display_sig, interpolation='nearest', origin='low', cmap = 'jet', norm=LogNorm())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build DNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#background\n",
    "display_bkg = bkg_trainimages.reshape(grid,grid)\n",
    "plt.grid(False)\n",
    "plt.imshow(display_bkg, interpolation='nearest', origin='low', cmap = 'jet', norm=LogNorm())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input1 = layers.Input(shape = (grid, grid, 1), name = 'input')\n",
    "    x = layers.Conv2D(64, (12, 12), padding = 'same', activation='relu', name = 'conv1')(input1)\n",
    "    x = layers.Conv2D(64, (6, 6), padding = 'same', activation='relu', name = 'conv2')(x)\n",
    "    x = layers.Conv2D(64, (4, 4), padding = 'same', activation='relu', name = 'conv3')(x)\n",
    "    x = layers.MaxPool2D((2, 2), name = 'maxpool1')(x)\n",
    "#     x = layers.Conv2D(32, (4, 4), padding = 'same', activation='relu', name = 'conv4')(x)\n",
    "#     x = layers.Conv2D(32, (3, 3), padding = 'same', activation='relu', name = 'conv5')(x)\n",
    "#     x = layers.Conv2D(32, (2, 2), padding = 'same', activation='relu', name = 'conv6')(x)\n",
    "#     x = layers.MaxPool2D((2, 2), name = 'maxpool2')(x)\n",
    "    x = layers.Flatten(name = 'flatten')(x)\n",
    "#     x = layers.Dense(64, activation='relu', name = 'relu1')(x)\n",
    "#     x = layers.Dense(256, activation='relu', name = 'relu2')(x)\n",
    "    x = layers.Dense(256, activation='relu', name = 'relu3')(x)\n",
    "    output = layers.Dense(2, activation='softmax', name = 'softmax')(x)\n",
    "    model = models.Model(inputs=input1, outputs=output)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['categorical_crossentropy', 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model's prediction $before$ training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = trainimages[::300]\n",
    "example_labels = trainlabels[::300]\n",
    "# example_radii = trainradii[:10]\n",
    "# example_theta = traintheta[:10]\n",
    "# example_z = trainz[:10]\n",
    "example_result = CNN.predict(x = example_batch)\n",
    "results = CNN.evaluate(x = example_batch, y = example_labels, verbose = 0)\n",
    "print(example_result)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"model/CNN_images1.h5\"\n",
    "if not os.path.exists(\"model\"):\n",
    "    os.mkdir(\"model\")\n",
    "\n",
    "# Create checkpoint callback\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "#                                                  save_best_only=True,\n",
    "#                                                  verbose=1)\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_loss', \n",
    "                                   verbose=1, save_best_only=True, \n",
    "                                   save_weights_only=False, mode='auto')    \n",
    "EPOCHS = 50\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = CNN.fit(\n",
    "  trainimages, trainlabels,\n",
    "  epochs=EPOCHS, validation_data = (valimages, vallabels), verbose = 1,\n",
    "  callbacks=[early_stop, model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a plot that shows the pregression of accuracy through each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_history(history):\n",
    "#   hist = pd.DataFrame(history.history)\n",
    "#   hist['epoch'] = history.epoch\n",
    "  \n",
    "#   plt.figure()\n",
    "#   plt.xlabel('Epoch')\n",
    "#   plt.ylabel('Mean Square Error')\n",
    "#   plt.plot(hist['epoch'], hist['binary'],\n",
    "#            label='Train Error')\n",
    "#   plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
    "#            label = 'Val Error')\n",
    "#   plt.ylim([0,100])\n",
    "#   plt.legend()\n",
    "#   plt.show()\n",
    "\n",
    "# plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load best weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls model\n",
    "best_model = keras.models.load_model('model/CNN_images1.h5')\n",
    "best_model.summary()\n",
    "results = best_model.evaluate(testimages, testlabels, verbose = 0)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of our DNN! Plot predictions vs. true values (the line is predictions vs. predicitons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = best_model.predict(testimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(testlabels[:,1], predict[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, lw=2, color='b', label='auc = %.3f' % (roc_auc))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='random chance')\n",
    "plt.xlim([0, 1.0])\n",
    "plt.ylim([0, 1.0])\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.title('receiver operating curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indqcd = np.argwhere(testlabels[:,1] == 0)\n",
    "ind1  = np.where(testlabels[:,1] == 1) \n",
    "# ind2  = np.where(testlabels[:,2] == 1)\n",
    "# ind3  = np.where(testlabels[:,3] == 1)\n",
    "hist_, bin_edges_ = np.histogram(predict[indqcd])\n",
    "plt.hist([predict[indqcd, 0].flatten(),predict[ind1, 1].flatten()] , histtype = 'step', label = ['qcd', 'ZZ'])\n",
    "plt.legend()\n",
    "plt.title('Predictions w/o normalized Pt')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Prediction (correct = 1)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
